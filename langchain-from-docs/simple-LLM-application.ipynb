{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "92e0eaf0",
   "metadata": {},
   "source": [
    "# Build a simple LLM application with chat models and prompt templates"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2f85ecf",
   "metadata": {},
   "source": [
    "# https://python.langchain.com/docs/tutorials/llm_chain/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86f88bac",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -U langchain langchain-openai\n",
    "!pip install -U langchain_experimental"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8a389966",
   "metadata": {},
   "outputs": [],
   "source": [
    "from secrets_langchain import LANGSMITH_TRACING, LANGSMITH_API_KEY, LANGSMITH_PROJECT, OPENAI_API_KEY\n",
    "import os\n",
    "os.environ[\"LANGSMITH_TRACING\"] = LANGSMITH_TRACING\n",
    "os.environ[\"LANGSMITH_API_KEY\"] = LANGSMITH_API_KEY\n",
    "os.environ[\"LANGSMITH_PROJECT\"] = LANGSMITH_PROJECT\n",
    "os.environ[\"OPENAI_API_KEY\"] = OPENAI_API_KEY  # Replace with your actual OpenAI API key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "435fa635",
   "metadata": {},
   "outputs": [],
   "source": [
    "import getpass\n",
    "import os\n",
    "\n",
    "try:\n",
    "    # load environment variables from .env file (requires `python-dotenv`)\n",
    "    from dotenv import load_dotenv\n",
    "\n",
    "    load_dotenv()\n",
    "except ImportError:\n",
    "    pass\n",
    "\n",
    "os.environ[\"LANGSMITH_TRACING\"] = \"true\"\n",
    "if \"LANGSMITH_API_KEY\" not in os.environ:\n",
    "    os.environ[\"LANGSMITH_API_KEY\"] = getpass.getpass(\n",
    "        prompt=\"Enter your LangSmith API key (optional): \"\n",
    "    )\n",
    "if \"LANGSMITH_PROJECT\" not in os.environ:\n",
    "    os.environ[\"LANGSMITH_PROJECT\"] = getpass.getpass(\n",
    "        prompt='Enter your LangSmith Project Name (default = \"default\"): '\n",
    "    )\n",
    "    if not os.environ.get(\"LANGSMITH_PROJECT\"):\n",
    "        os.environ[\"LANGSMITH_PROJECT\"] = \"default\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e2e13a8",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "24758ff0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import getpass\n",
    "import os\n",
    "\n",
    "if not os.environ.get(\"OPENAI_API_KEY\"):\n",
    "  os.environ[\"OPENAI_API_KEY\"] = getpass.getpass(\"Enter API key for OpenAI: \")\n",
    "\n",
    "from langchain.chat_models import init_chat_model\n",
    "\n",
    "model = init_chat_model(\"gpt-4o-mini\", model_provider=\"openai\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "366a8210",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Willkommen beim LangChain Python API-Referenz. Dies ist eine Referenz für alle langchain-x Pakete.', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 24, 'prompt_tokens': 38, 'total_tokens': 62, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_34a54ae93c', 'id': 'chatcmpl-BqglBQzAHPNQERodR82FgVWqwZRTl', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='run--bb0c7a83-016c-4be1-8e7a-16f50a2a3068-0', usage_metadata={'input_tokens': 38, 'output_tokens': 24, 'total_tokens': 62, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.messages import HumanMessage, SystemMessage\n",
    "\n",
    "messages = [\n",
    "    SystemMessage(\"Translate the following from English into German\"),\n",
    "    # HumanMessage(\"Hello, how are you? I hope you are having a great day!\"),\n",
    "    HumanMessage(\"Welcome to the LangChain Python API reference. This is a reference for all langchain-x packages.\"),\n",
    "]\n",
    "\n",
    "model.invoke(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8998c557",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Hello! How can I assist you today?', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 9, 'prompt_tokens': 8, 'total_tokens': 17, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_34a54ae93c', 'id': 'chatcmpl-Bqgp0Gg9Ti6FkT96zf2PZm3hHbgH6', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='run--57e20a47-aac8-4e3b-9418-a3e7fe6312f1-0', usage_metadata={'input_tokens': 8, 'output_tokens': 9, 'total_tokens': 17, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.invoke(\"Hello\")\n",
    "\n",
    "model.invoke([{\"role\": \"user\", \"content\": \"Hello\"}])\n",
    "\n",
    "model.invoke([HumanMessage(\"Hello\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "157b3111",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|Will|kommen| zur| Lang|Chain| Python| API|-|Refer|enz|.| Dies| ist| ein| Refer|enz|d|okument| für| alle| lang|chain|-x| Pak|ete|.||"
     ]
    }
   ],
   "source": [
    "#Streaming\n",
    "\n",
    "for token in model.stream(messages):\n",
    "    print(token.content, end=\"|\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4ec4eb2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import getpass\n",
    "import os\n",
    "\n",
    "if not os.environ.get(\"OPENAI_API_KEY\"):\n",
    "  os.environ[\"OPENAI_API_KEY\"] = getpass.getpass(\"Enter API key for OpenAI: \")\n",
    "\n",
    "from langchain.chat_models import init_chat_model\n",
    "\n",
    "model = init_chat_model(\"gpt-4o-mini\", model_provider=\"openai\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ba2585c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Hello! How can I assist you today?', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 9, 'prompt_tokens': 11, 'total_tokens': 20, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_34a54ae93c', 'id': 'chatcmpl-BqgtDpQlMOQMCjIjvxWZvwbSWS1fS', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='run--f5186d92-11a8-47c8-9e56-b6197e362c09-0', usage_metadata={'input_tokens': 11, 'output_tokens': 9, 'total_tokens': 20, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.invoke(\"Hello, world!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "332ad575",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_experimental.openai_assistant import OpenAIAssistantRunnable\n",
    "\n",
    "interpreter_assistant = OpenAIAssistantRunnable.create_assistant(\n",
    "    name=\"langchain assistant\",\n",
    "    instructions=\"You are a personal math tutor. Write and run code to answer math questions.\",\n",
    "    tools=[{\"type\": \"code_interpreter\"}],\n",
    "    model=\"gpt-4-1106-preview\"\n",
    ")\n",
    "output = interpreter_assistant.invoke({\"content\": \"What's 10 - 4 raised to the 2.7\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f4db4605",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Message(id='msg_bkfpRW4LNy5PUEOUxXxxR8LB', assistant_id='asst_YHL01ASOGNDZVqKx7OWzSy89', attachments=[], completed_at=None, content=[TextContentBlock(text=Text(annotations=[], value='The result of \\\\( 10 - 4^{2.7} \\\\) is approximately \\\\(-32.22\\\\).'), type='text')], created_at=1751897789, incomplete_at=None, incomplete_details=None, metadata={}, object='thread.message', role='assistant', run_id='run_OS4XYi6Ev7ijy0tgZimJwyFy', status=None, thread_id='thread_lByPo5KPoVWehn2CZpZS3PV3')]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "77dbea6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HELLO WORLD\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.runnables import RunnableLambda\n",
    "\n",
    "# A simple Runnable that uppercases input\n",
    "runnable = RunnableLambda(lambda x: x.upper())\n",
    "\n",
    "output = runnable.invoke(\"hello world\")\n",
    "print(output)  # HELLO WORLD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1000a1db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='The capital of Germany is Berlin.' additional_kwargs={} response_metadata={'token_usage': {'completion_tokens': 7, 'prompt_tokens': 14, 'total_tokens': 21, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-3.5-turbo', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None} id='run--96d43c61-d9cb-48b9-a697-a0364fce14ca-0'\n"
     ]
    }
   ],
   "source": [
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "# from langchain.output_parsers import StrOutputParser\n",
    "\n",
    "prompt = ChatPromptTemplate.from_template(\"What is the capital of {country}?\")\n",
    "model = ChatOpenAI()\n",
    "# parser = StrOutputParser()\n",
    "\n",
    "chain = prompt | model   # This is a RunnableSequence\n",
    "\n",
    "print(chain.invoke({\"country\": \"Germany\"}))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "790e7baf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prompt template\n",
    "\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "system_template = \"Translate the following from English into {language}\"\n",
    "\n",
    "prompt_template = ChatPromptTemplate.from_messages(\n",
    "    [(\"system\", system_template), (\"user\", \"{text}\")]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e2e4e40c",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = prompt_template.invoke({\"language\": \"German\", \"text\": \"hello, how are you?\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "541fc967",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatPromptValue(messages=[SystemMessage(content='Translate the following from English into German', additional_kwargs={}, response_metadata={}), HumanMessage(content='hello, how are you?', additional_kwargs={}, response_metadata={})])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "03b9dc0a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[SystemMessage(content='Translate the following from English into German', additional_kwargs={}, response_metadata={}),\n",
       " HumanMessage(content='hello, how are you?', additional_kwargs={}, response_metadata={})]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt.to_messages()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "48fdb815",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hallo, wie geht es dir?\n"
     ]
    }
   ],
   "source": [
    "response = model.invoke(prompt)\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfd2f3e9",
   "metadata": {},
   "source": [
    "# Build a semantic search engine i.e RAG RETRIEVAL AUGEMENTED GENERATION\n",
    "# https://python.langchain.com/docs/tutorials/retrievers/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04200d6b",
   "metadata": {},
   "source": [
    "This tutorial will familiarize you with LangChain's document loader, embedding, and vector store abstractions. These abstractions are designed to support retrieval of data-- from (vector) databases and other sources-- for integration with LLM workflows. They are important for applications that fetch data to be reasoned over as part of model inference, as in the case of retrieval-augmented generation, or RAG (see our RAG tutorial here).\n",
    "\n",
    "This guide focuses on retrieval of text data. We will cover the following concepts:\n",
    "\n",
    "Documents and document loaders;\n",
    "Text splitters;\n",
    "Embeddings;\n",
    "Vector stores and retrievers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ce974cce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install langchain-community pypdf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36e7f416",
   "metadata": {},
   "source": [
    "Documents and Document Loaders\n",
    "LangChain implements a Document abstraction, which is intended to represent a unit of text and associated metadata. It has three attributes:\n",
    "\n",
    "page_content: a string representing the content;\n",
    "metadata: a dict containing arbitrary metadata;\n",
    "id: (optional) a string identifier for the document.\n",
    "The metadata attribute can capture information about the source of the document, its relationship to other documents, and other information. Note that an individual Document object often represents a chunk of a larger document."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "27070b81",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.documents import Document\n",
    "\n",
    "documents = [\n",
    "    Document(\n",
    "        page_content=\"Dogs are great companions, known for their loyalty and friendliness.\",\n",
    "        metadata={\"source\": \"mammal-pets-doc\"},\n",
    "    ),\n",
    "    Document(\n",
    "        page_content=\"Cats are independent pets that often enjoy their own space.\",\n",
    "        metadata={\"source\": \"mammal-pets-doc\"},\n",
    "    ),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "867a0567",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "107\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "\n",
    "file_path = \"example_data/nke-10k-2023.pdf\"\n",
    "loader = PyPDFLoader(file_path)\n",
    "\n",
    "docs = loader.load()\n",
    "\n",
    "print(len(docs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "3367d3e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Table of Contents\n",
      "UNITED STATES\n",
      "SECURITIES AND EXCHANGE COMMISSION\n",
      "Washington, D.C. 20549\n",
      "FORM 10-K\n",
      "(Mark One)\n",
      "☑  ANNUAL REPORT PURSUANT TO SECTION 13 OR 15(D) OF THE SECURITIES EXCHANGE ACT OF 1934\n",
      "F\n",
      "\n",
      "{'producer': 'EDGRpdf Service w/ EO.Pdf 22.0.40.0', 'creator': 'EDGAR Filing HTML Converter', 'creationdate': '2023-07-20T16:22:00-04:00', 'title': '0000320187-23-000039', 'author': 'EDGAR Online, a division of Donnelley Financial Solutions', 'subject': 'Form 10-K filed on 2023-07-20 for the period ending 2023-05-31', 'keywords': '0000320187-23-000039; ; 10-K', 'moddate': '2023-07-20T16:22:08-04:00', 'source': 'example_data/nke-10k-2023.pdf', 'total_pages': 107, 'page': 0, 'page_label': '1'}\n"
     ]
    }
   ],
   "source": [
    "print(f\"{docs[0].page_content[:200]}\\n\")\n",
    "print(docs[0].metadata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "fcdd24dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "516"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=1000, chunk_overlap=200, add_start_index=True\n",
    ")\n",
    "all_splits = text_splitter.split_documents(docs)\n",
    "\n",
    "len(all_splits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "6cac3f02",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Embeddings\n",
    "import getpass\n",
    "import os\n",
    "\n",
    "if not os.environ.get(\"OPENAI_API_KEY\"):\n",
    "  os.environ[\"OPENAI_API_KEY\"] = getpass.getpass(\"Enter API key for OpenAI: \")\n",
    "\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "\n",
    "embeddings = OpenAIEmbeddings(model=\"text-embedding-3-large\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "43136f20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated vectors of length 3072\n",
      "\n",
      "[0.009286928921937943, -0.015886522829532623, 0.0003275189083069563, 0.00636835815384984, 0.020573733374476433, -0.03912259265780449, -0.007468290627002716, 0.040972478687763214, -0.007899514399468899, 0.05984631925821304]\n"
     ]
    }
   ],
   "source": [
    "vector_1 = embeddings.embed_query(all_splits[0].page_content)\n",
    "vector_2 = embeddings.embed_query(all_splits[1].page_content)\n",
    "\n",
    "assert len(vector_1) == len(vector_2)\n",
    "print(f\"Generated vectors of length {len(vector_1)}\\n\")\n",
    "print(vector_1[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "944a8d15",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.0.1 -> 25.1.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "# Vector stores\n",
    "\n",
    "!pip install -qU langchain-core langchain-chroma\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "18a7d59f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# VECTOR STORE IN MEMORY\n",
    "from langchain_core.vectorstores import InMemoryVectorStore\n",
    "\n",
    "vector_store = InMemoryVectorStore(embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "39706b70",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_chroma import Chroma\n",
    "\n",
    "vector_store = Chroma(\n",
    "    collection_name=\"example_collection\",\n",
    "    embedding_function=embeddings,\n",
    "    persist_directory=\"./chroma_langchain_db\",  # Where to save data locally, remove if not necessary\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "e4f3e8a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "ids = vector_store.add_documents(documents=all_splits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "83e59197",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "516"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "b71f8e9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "page_content='operations. We also lease an office complex in Shanghai, China, our headquarters for our Greater China geography, occupied by employees focused on implementing our\n",
      "wholesale, NIKE Direct and merchandising strategies in the region, among other functions.\n",
      "In the United States, NIKE has eight significant distribution centers. Five are located in or near Memphis, Tennessee, two of which are owned and three of which are\n",
      "leased. Two other distribution centers, one located in Indianapolis, Indiana and one located in Dayton, Tennessee, are leased and operated by third-party logistics\n",
      "providers. One distribution center for Converse is located in Ontario, California, which is leased. NIKE has a number of distribution facilities outside the United States,\n",
      "some of which are leased and operated by third-party logistics providers. The most significant distribution facilities outside the United States are located in Laakdal,' metadata={'moddate': '2023-07-20T16:22:08-04:00', 'producer': 'EDGRpdf Service w/ EO.Pdf 22.0.40.0', 'page_label': '27', 'source': 'example_data/nke-10k-2023.pdf', 'title': '0000320187-23-000039', 'author': 'EDGAR Online, a division of Donnelley Financial Solutions', 'creator': 'EDGAR Filing HTML Converter', 'page': 26, 'subject': 'Form 10-K filed on 2023-07-20 for the period ending 2023-05-31', 'keywords': '0000320187-23-000039; ; 10-K', 'creationdate': '2023-07-20T16:22:00-04:00', 'total_pages': 107, 'start_index': 804}\n"
     ]
    }
   ],
   "source": [
    "results = vector_store.similarity_search(\n",
    "    \"How many distribution centers does Nike have in the US?\"\n",
    ")\n",
    "\n",
    "print(results[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "710457ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "page_content='direct to consumer operations sell products through the following number of retail stores in the United States:\n",
      "U.S. RETAIL STORES NUMBER\n",
      "NIKE Brand factory stores 213 \n",
      "NIKE Brand in-line stores (including employee-only stores) 74 \n",
      "Converse stores (including factory stores) 82 \n",
      "TOTAL 369 \n",
      "In the United States, NIKE has eight significant distribution centers. Refer to Item 2. Properties for further information.\n",
      "2023 FORM 10-K 2' metadata={'creator': 'EDGAR Filing HTML Converter', 'producer': 'EDGRpdf Service w/ EO.Pdf 22.0.40.0', 'keywords': '0000320187-23-000039; ; 10-K', 'page_label': '5', 'creationdate': '2023-07-20T16:22:00-04:00', 'start_index': 3125, 'source': 'example_data/nke-10k-2023.pdf', 'page': 4, 'total_pages': 107, 'author': 'EDGAR Online, a division of Donnelley Financial Solutions', 'moddate': '2023-07-20T16:22:08-04:00', 'title': '0000320187-23-000039', 'subject': 'Form 10-K filed on 2023-07-20 for the period ending 2023-05-31'}\n"
     ]
    }
   ],
   "source": [
    "results = vector_store.similarity_search(\n",
    "    \"How many distribution centers does Nike have in the US, give me just number|?\"\n",
    ")\n",
    "\n",
    "print(results[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "3849d069",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "page_content='Table of Contents\n",
      "PART I\n",
      "ITEM 1. BUSINESS\n",
      "GENERAL\n",
      "NIKE, Inc. was incorporated in 1967 under the laws of the State of Oregon. As used in this Annual Report on Form 10-K (this \"Annual Report\"), the terms \"we,\" \"us,\" \"our,\"\n",
      "\"NIKE\" and the \"Company\" refer to NIKE, Inc. and its predecessors, subsidiaries and affiliates, collectively, unless the context indicates otherwise.\n",
      "Our principal business activity is the design, development and worldwide marketing and selling of athletic footwear, apparel, equipment, accessories and services. NIKE is\n",
      "the largest seller of athletic footwear and apparel in the world. We sell our products through NIKE Direct operations, which are comprised of both NIKE-owned retail stores\n",
      "and sales through our digital platforms (also referred to as \"NIKE Brand Digital\"), to retail accounts and to a mix of independent distributors, licensees and sales' metadata={'producer': 'EDGRpdf Service w/ EO.Pdf 22.0.40.0', 'creator': 'EDGAR Filing HTML Converter', 'total_pages': 107, 'start_index': 0, 'moddate': '2023-07-20T16:22:08-04:00', 'author': 'EDGAR Online, a division of Donnelley Financial Solutions', 'page_label': '4', 'subject': 'Form 10-K filed on 2023-07-20 for the period ending 2023-05-31', 'creationdate': '2023-07-20T16:22:00-04:00', 'page': 3, 'keywords': '0000320187-23-000039; ; 10-K', 'source': 'example_data/nke-10k-2023.pdf', 'title': '0000320187-23-000039'}\n"
     ]
    }
   ],
   "source": [
    "results = await vector_store.asimilarity_search(\"When was Nike incorporated?\")\n",
    "\n",
    "print(results[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "4728583f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score: 0.6235305666923523\n",
      "\n",
      "page_content='Table of Contents\n",
      "FISCAL 2023 NIKE BRAND REVENUE HIGHLIGHTSThe following tables present NIKE Brand revenues disaggregated by reportable operating segment, distribution channel and major product line:\n",
      "FISCAL 2023 COMPARED TO FISCAL 2022\n",
      "• NIKE, Inc. Revenues were $51.2 billion in fiscal 2023, which increased 10% and 16% compared to fiscal 2022 on a reported and currency-neutral basis, respectively.\n",
      "The increase was due to higher revenues in North America, Europe, Middle East & Africa (\"EMEA\"), APLA and Greater China, which contributed approximately 7, 6,\n",
      "2 and 1 percentage points to NIKE, Inc. Revenues, respectively.\n",
      "• NIKE Brand revenues, which represented over 90% of NIKE, Inc. Revenues, increased 10% and 16% on a reported and currency-neutral basis, respectively. This\n",
      "increase was primarily due to higher revenues in Men's, the Jordan Brand, Women's and Kids' which grew 17%, 35%,11% and 10%, respectively, on a wholesale\n",
      "equivalent basis.' metadata={'creator': 'EDGAR Filing HTML Converter', 'producer': 'EDGRpdf Service w/ EO.Pdf 22.0.40.0', 'keywords': '0000320187-23-000039; ; 10-K', 'title': '0000320187-23-000039', 'page': 35, 'source': 'example_data/nke-10k-2023.pdf', 'author': 'EDGAR Online, a division of Donnelley Financial Solutions', 'total_pages': 107, 'moddate': '2023-07-20T16:22:08-04:00', 'subject': 'Form 10-K filed on 2023-07-20 for the period ending 2023-05-31', 'page_label': '36', 'start_index': 0, 'creationdate': '2023-07-20T16:22:00-04:00'}\n"
     ]
    }
   ],
   "source": [
    "results = vector_store.similarity_search_with_score(\"What was Nike's revenue in 2023?\")\n",
    "doc, score = results[0]\n",
    "print(f\"Score: {score}\\n\")\n",
    "print(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "b7678521",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "page_content='Table of Contents\n",
      "GROSS MARGIN\n",
      "FISCAL 2023 COMPARED TO FISCAL 2022\n",
      "For fiscal 2023, our consolidated gross profit increased 4% to $22,292 million compared to $21,479 million for fiscal 2022. Gross margin decreased 250 basis points to\n",
      "43.5% for fiscal 2023 compared to 46.0% for fiscal 2022 due to the following:\n",
      "*Wholesale equivalent\n",
      "The decrease in gross margin for fiscal 2023 was primarily due to:\n",
      "• Higher NIKE Brand product costs, on a wholesale equivalent basis, primarily due to higher input costs and elevated inbound freight and logistics costs as well as\n",
      "product mix;\n",
      "• Lower margin in our NIKE Direct business, driven by higher promotional activity to liquidate inventory in the current period compared to lower promotional activity in\n",
      "the prior period resulting from lower available inventory supply;\n",
      "• Unfavorable changes in net foreign currency exchange rates, including hedges; and\n",
      "• Lower off-price margin, on a wholesale equivalent basis.\n",
      "This was partially offset by:' metadata={'creationdate': '2023-07-20T16:22:00-04:00', 'subject': 'Form 10-K filed on 2023-07-20 for the period ending 2023-05-31', 'keywords': '0000320187-23-000039; ; 10-K', 'producer': 'EDGRpdf Service w/ EO.Pdf 22.0.40.0', 'page_label': '37', 'creator': 'EDGAR Filing HTML Converter', 'author': 'EDGAR Online, a division of Donnelley Financial Solutions', 'total_pages': 107, 'start_index': 0, 'title': '0000320187-23-000039', 'moddate': '2023-07-20T16:22:08-04:00', 'source': 'example_data/nke-10k-2023.pdf', 'page': 36}\n"
     ]
    }
   ],
   "source": [
    "embedding = embeddings.embed_query(\"How were Nike's margins impacted in 2023?\")\n",
    "\n",
    "results = vector_store.similarity_search_by_vector(embedding)\n",
    "print(results[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "77d6a682",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[Document(id='5ad468c1-2a7a-4a21-8068-bba009808186', metadata={'producer': 'EDGRpdf Service w/ EO.Pdf 22.0.40.0', 'keywords': '0000320187-23-000039; ; 10-K', 'creationdate': '2023-07-20T16:22:00-04:00', 'source': 'example_data/nke-10k-2023.pdf', 'start_index': 804, 'subject': 'Form 10-K filed on 2023-07-20 for the period ending 2023-05-31', 'moddate': '2023-07-20T16:22:08-04:00', 'total_pages': 107, 'page': 26, 'author': 'EDGAR Online, a division of Donnelley Financial Solutions', 'creator': 'EDGAR Filing HTML Converter', 'page_label': '27', 'title': '0000320187-23-000039'}, page_content='operations. We also lease an office complex in Shanghai, China, our headquarters for our Greater China geography, occupied by employees focused on implementing our\\nwholesale, NIKE Direct and merchandising strategies in the region, among other functions.\\nIn the United States, NIKE has eight significant distribution centers. Five are located in or near Memphis, Tennessee, two of which are owned and three of which are\\nleased. Two other distribution centers, one located in Indianapolis, Indiana and one located in Dayton, Tennessee, are leased and operated by third-party logistics\\nproviders. One distribution center for Converse is located in Ontario, California, which is leased. NIKE has a number of distribution facilities outside the United States,\\nsome of which are leased and operated by third-party logistics providers. The most significant distribution facilities outside the United States are located in Laakdal,')],\n",
       " [Document(id='0c2968dd-1677-48d4-9e5e-7c25ef758792', metadata={'total_pages': 107, 'source': 'example_data/nke-10k-2023.pdf', 'page': 3, 'author': 'EDGAR Online, a division of Donnelley Financial Solutions', 'start_index': 0, 'subject': 'Form 10-K filed on 2023-07-20 for the period ending 2023-05-31', 'creationdate': '2023-07-20T16:22:00-04:00', 'title': '0000320187-23-000039', 'page_label': '4', 'producer': 'EDGRpdf Service w/ EO.Pdf 22.0.40.0', 'creator': 'EDGAR Filing HTML Converter', 'moddate': '2023-07-20T16:22:08-04:00', 'keywords': '0000320187-23-000039; ; 10-K'}, page_content='Table of Contents\\nPART I\\nITEM 1. BUSINESS\\nGENERAL\\nNIKE, Inc. was incorporated in 1967 under the laws of the State of Oregon. As used in this Annual Report on Form 10-K (this \"Annual Report\"), the terms \"we,\" \"us,\" \"our,\"\\n\"NIKE\" and the \"Company\" refer to NIKE, Inc. and its predecessors, subsidiaries and affiliates, collectively, unless the context indicates otherwise.\\nOur principal business activity is the design, development and worldwide marketing and selling of athletic footwear, apparel, equipment, accessories and services. NIKE is\\nthe largest seller of athletic footwear and apparel in the world. We sell our products through NIKE Direct operations, which are comprised of both NIKE-owned retail stores\\nand sales through our digital platforms (also referred to as \"NIKE Brand Digital\"), to retail accounts and to a mix of independent distributors, licensees and sales')]]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# runnable example\n",
    "\n",
    "from typing import List\n",
    "\n",
    "from langchain_core.documents import Document\n",
    "from langchain_core.runnables import chain\n",
    "\n",
    "\n",
    "@chain\n",
    "def retriever(query: str) -> List[Document]:\n",
    "    return vector_store.similarity_search(query, k=1)\n",
    "\n",
    "\n",
    "retriever.batch(\n",
    "    [\n",
    "        \"How many distribution centers does Nike have in the US?\",\n",
    "        \"When was Nike incorporated?\",\n",
    "    ],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c5baea6",
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = vector_store.as_retriever(\n",
    "    search_type=\"similarity\",\n",
    "    search_kwargs={\"k\": 1},\n",
    ")\n",
    "\n",
    "retriever.batch(\n",
    "    [\n",
    "        \"How many distribution centers does Nike have in the US?\",\n",
    "        \"When was Nike incorporated?\",\n",
    "    ],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d602c34",
   "metadata": {},
   "source": [
    "# https://python.langchain.com/docs/how_to/structured_output/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfa3f3ad",
   "metadata": {},
   "source": [
    "# streaming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "2a65cc0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "first=RunnableBinding(bound=ChatOpenAI(client=<openai.resources.chat.completions.completions.Completions object at 0x000002972D9F0340>, async_client=<openai.resources.chat.completions.completions.AsyncCompletions object at 0x000002972D9F3D90>, root_client=<openai.OpenAI object at 0x000002972D9F05B0>, root_async_client=<openai.AsyncOpenAI object at 0x000002972D9F3340>, model_name='gpt-4o-mini', model_kwargs={}, openai_api_key=SecretStr('**********')), kwargs={'response_format': {'type': 'json_schema', 'json_schema': {'name': 'Joke', 'description': 'Joke to tell user.', 'strict': False, 'schema': {'type': 'object', 'properties': {'setup': {'description': 'The setup of the joke', 'type': 'string'}, 'punchline': {'description': 'The punchline of the joke', 'type': 'string'}, 'rating': {'description': 'How funny the joke is, from 1 to 10', 'type': 'integer'}}, 'required': ['setup', 'punchline']}}}, 'ls_structured_output_format': {'kwargs': {'method': 'json_schema', 'strict': None}, 'schema': {'type': 'function', 'function': {'name': 'Joke', 'description': 'Joke to tell user.', 'parameters': {'type': 'object', 'properties': {'setup': {'description': 'The setup of the joke', 'type': 'string'}, 'punchline': {'description': 'The punchline of the joke', 'type': 'string'}, 'rating': {'description': 'How funny the joke is, from 1 to 10', 'type': 'integer'}}, 'required': ['setup', 'punchline']}}}}}, config={}, config_factories=[]) middle=[] last=JsonOutputParser()\n",
      "{}\n",
      "{'setup': ''}\n",
      "{'setup': 'Why'}\n",
      "{'setup': 'Why did'}\n",
      "{'setup': 'Why did the'}\n",
      "{'setup': 'Why did the cat'}\n",
      "{'setup': 'Why did the cat sit'}\n",
      "{'setup': 'Why did the cat sit on'}\n",
      "{'setup': 'Why did the cat sit on the'}\n",
      "{'setup': 'Why did the cat sit on the computer'}\n",
      "{'setup': 'Why did the cat sit on the computer?'}\n",
      "{'setup': 'Why did the cat sit on the computer?', 'punchline': ''}\n",
      "{'setup': 'Why did the cat sit on the computer?', 'punchline': 'Because'}\n",
      "{'setup': 'Why did the cat sit on the computer?', 'punchline': 'Because it'}\n",
      "{'setup': 'Why did the cat sit on the computer?', 'punchline': 'Because it wanted'}\n",
      "{'setup': 'Why did the cat sit on the computer?', 'punchline': 'Because it wanted to'}\n",
      "{'setup': 'Why did the cat sit on the computer?', 'punchline': 'Because it wanted to keep'}\n",
      "{'setup': 'Why did the cat sit on the computer?', 'punchline': 'Because it wanted to keep an'}\n",
      "{'setup': 'Why did the cat sit on the computer?', 'punchline': 'Because it wanted to keep an eye'}\n",
      "{'setup': 'Why did the cat sit on the computer?', 'punchline': 'Because it wanted to keep an eye on'}\n",
      "{'setup': 'Why did the cat sit on the computer?', 'punchline': 'Because it wanted to keep an eye on the'}\n",
      "{'setup': 'Why did the cat sit on the computer?', 'punchline': 'Because it wanted to keep an eye on the mouse'}\n",
      "{'setup': 'Why did the cat sit on the computer?', 'punchline': 'Because it wanted to keep an eye on the mouse!'}\n",
      "{'setup': 'Why did the cat sit on the computer?', 'punchline': 'Because it wanted to keep an eye on the mouse!', 'rating': 7}\n"
     ]
    }
   ],
   "source": [
    "from typing_extensions import Annotated, TypedDict\n",
    "from typing import Optional, Union\n",
    "llm = init_chat_model(\"gpt-4o-mini\", model_provider=\"openai\")\n",
    "# TypedDict\n",
    "class Joke(TypedDict):\n",
    "    \"\"\"Joke to tell user.\"\"\"\n",
    "\n",
    "    setup: Annotated[str, ..., \"The setup of the joke\"]\n",
    "    punchline: Annotated[str, ..., \"The punchline of the joke\"]\n",
    "    rating: Annotated[Optional[int], None, \"How funny the joke is, from 1 to 10\"]\n",
    "\n",
    "\n",
    "structured_llm = llm.with_structured_output(Joke)\n",
    "print(structured_llm)\n",
    "for chunk in structured_llm.stream(\"Tell me a joke about cats\"):\n",
    "    print(chunk)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b102a32c",
   "metadata": {},
   "source": [
    "Few-shot prompting\n",
    "For more complex schemas it's very useful to add few-shot examples to the prompt. This can be done in a few ways.\n",
    "\n",
    "The simplest and most universal way is to add examples to a system message in the prompt:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "85db5186",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'setup': 'Woodpecker',\n",
       " 'punchline': \"Woodpecker knock twice, but he's just looking for a good time to peck out a tune!\",\n",
       " 'rating': 6}"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "system = \"\"\"You are a hilarious comedian. Your specialty is knock-knock jokes. \\\n",
    "Return a joke which has the setup (the response to \"Who's there?\") and the final punchline (the response to \"<setup> who?\").\n",
    "\n",
    "Here are some examples of jokes:\n",
    "\n",
    "example_user: Tell me a joke about planes\n",
    "example_assistant: {{\"setup\": \"Why don't planes ever get tired?\", \"punchline\": \"Because they have rest wings!\", \"rating\": 2}}\n",
    "\n",
    "example_user: Tell me another joke about planes\n",
    "example_assistant: {{\"setup\": \"Cargo\", \"punchline\": \"Cargo 'vroom vroom', but planes go 'zoom zoom'!\", \"rating\": 10}}\n",
    "\n",
    "example_user: Now about caterpillars\n",
    "example_assistant: {{\"setup\": \"Caterpillar\", \"punchline\": \"Caterpillar really slow, but watch me turn into a butterfly and steal the show!\", \"rating\": 5}}\"\"\"\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages([(\"system\", system), (\"human\", \"{input}\")])\n",
    "\n",
    "few_shot_structured_llm = prompt | structured_llm\n",
    "few_shot_structured_llm.invoke(\"what's something funny about woodpeckers\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "d4873e41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{}\n",
      "{'setup': ''}\n",
      "{'setup': 'Wood'}\n",
      "{'setup': 'Woodpe'}\n",
      "{'setup': 'Woodpecker'}\n",
      "{'setup': 'Woodpecker', 'punchline': ''}\n",
      "{'setup': 'Woodpecker', 'punchline': 'Wood'}\n",
      "{'setup': 'Woodpecker', 'punchline': 'Woodpe'}\n",
      "{'setup': 'Woodpecker', 'punchline': 'Woodpecker'}\n",
      "{'setup': 'Woodpecker', 'punchline': 'Woodpecker knocked'}\n",
      "{'setup': 'Woodpecker', 'punchline': 'Woodpecker knocked,'}\n",
      "{'setup': 'Woodpecker', 'punchline': 'Woodpecker knocked, but'}\n",
      "{'setup': 'Woodpecker', 'punchline': 'Woodpecker knocked, but I'}\n",
      "{'setup': 'Woodpecker', 'punchline': 'Woodpecker knocked, but I let'}\n",
      "{'setup': 'Woodpecker', 'punchline': \"Woodpecker knocked, but I let '\"}\n",
      "{'setup': 'Woodpecker', 'punchline': \"Woodpecker knocked, but I let 'em\"}\n",
      "{'setup': 'Woodpecker', 'punchline': \"Woodpecker knocked, but I let 'em in\"}\n",
      "{'setup': 'Woodpecker', 'punchline': \"Woodpecker knocked, but I let 'em in because\"}\n",
      "{'setup': 'Woodpecker', 'punchline': \"Woodpecker knocked, but I let 'em in because they\"}\n",
      "{'setup': 'Woodpecker', 'punchline': \"Woodpecker knocked, but I let 'em in because they were\"}\n",
      "{'setup': 'Woodpecker', 'punchline': \"Woodpecker knocked, but I let 'em in because they were just\"}\n",
      "{'setup': 'Woodpecker', 'punchline': \"Woodpecker knocked, but I let 'em in because they were just all\"}\n",
      "{'setup': 'Woodpecker', 'punchline': \"Woodpecker knocked, but I let 'em in because they were just all about\"}\n",
      "{'setup': 'Woodpecker', 'punchline': \"Woodpecker knocked, but I let 'em in because they were just all about the\"}\n",
      "{'setup': 'Woodpecker', 'punchline': \"Woodpecker knocked, but I let 'em in because they were just all about the pe\"}\n",
      "{'setup': 'Woodpecker', 'punchline': \"Woodpecker knocked, but I let 'em in because they were just all about the peck\"}\n",
      "{'setup': 'Woodpecker', 'punchline': \"Woodpecker knocked, but I let 'em in because they were just all about the pecking\"}\n",
      "{'setup': 'Woodpecker', 'punchline': \"Woodpecker knocked, but I let 'em in because they were just all about the pecking order\"}\n",
      "{'setup': 'Woodpecker', 'punchline': \"Woodpecker knocked, but I let 'em in because they were just all about the pecking order!\"}\n",
      "{'setup': 'Woodpecker', 'punchline': \"Woodpecker knocked, but I let 'em in because they were just all about the pecking order!\", 'rating': 6}\n"
     ]
    }
   ],
   "source": [
    "# for streaming the above example\n",
    "for chunk in few_shot_structured_llm.stream(\"what's something funny about woodpeckers\"):\n",
    "    print(chunk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "19f9bc46",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'setup': 'Crocodile',\n",
       " 'punchline': \"Crocodile tears? Nah, just my way of saying 'I'm feeling a bit scale-y!','\",\n",
       " 'rating': 6}"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.messages import AIMessage, HumanMessage, ToolMessage\n",
    "\n",
    "examples = [\n",
    "    HumanMessage(\"Tell me a joke about planes\", name=\"example_user\"),\n",
    "    AIMessage(\n",
    "        \"\",\n",
    "        name=\"example_assistant\",\n",
    "        tool_calls=[\n",
    "            {\n",
    "                \"name\": \"joke\",\n",
    "                \"args\": {\n",
    "                    \"setup\": \"Why don't planes ever get tired?\",\n",
    "                    \"punchline\": \"Because they have rest wings!\",\n",
    "                    \"rating\": 2,\n",
    "                },\n",
    "                \"id\": \"1\",\n",
    "            }\n",
    "        ],\n",
    "    ),\n",
    "    # Most tool-calling models expect a ToolMessage(s) to follow an AIMessage with tool calls.\n",
    "    ToolMessage(\"\", tool_call_id=\"1\"),\n",
    "    # Some models also expect an AIMessage to follow any ToolMessages,\n",
    "    # so you may need to add an AIMessage here.\n",
    "    HumanMessage(\"Tell me another joke about planes\", name=\"example_user\"),\n",
    "    AIMessage(\n",
    "        \"\",\n",
    "        name=\"example_assistant\",\n",
    "        tool_calls=[\n",
    "            {\n",
    "                \"name\": \"joke\",\n",
    "                \"args\": {\n",
    "                    \"setup\": \"Cargo\",\n",
    "                    \"punchline\": \"Cargo 'vroom vroom', but planes go 'zoom zoom'!\",\n",
    "                    \"rating\": 10,\n",
    "                },\n",
    "                \"id\": \"2\",\n",
    "            }\n",
    "        ],\n",
    "    ),\n",
    "    ToolMessage(\"\", tool_call_id=\"2\"),\n",
    "    HumanMessage(\"Now about caterpillars\", name=\"example_user\"),\n",
    "    AIMessage(\n",
    "        \"\",\n",
    "        tool_calls=[\n",
    "            {\n",
    "                \"name\": \"joke\",\n",
    "                \"args\": {\n",
    "                    \"setup\": \"Caterpillar\",\n",
    "                    \"punchline\": \"Caterpillar really slow, but watch me turn into a butterfly and steal the show!\",\n",
    "                    \"rating\": 5,\n",
    "                },\n",
    "                \"id\": \"3\",\n",
    "            }\n",
    "        ],\n",
    "    ),\n",
    "    ToolMessage(\"\", tool_call_id=\"3\"),\n",
    "]\n",
    "system = \"\"\"You are a hilarious comedian. Your specialty is knock-knock jokes. \\\n",
    "Return a joke which has the setup (the response to \"Who's there?\") \\\n",
    "and the final punchline (the response to \"<setup> who?\").\"\"\"\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [(\"system\", system), (\"placeholder\", \"{examples}\"), (\"human\", \"{input}\")]\n",
    ")\n",
    "few_shot_structured_llm = prompt | structured_llm\n",
    "few_shot_structured_llm.invoke({\"input\": \"crocodiles\", \"examples\": examples})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "903e5df3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prompting and parsing model outputs directly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "21aa5cd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "\n",
    "from langchain_core.output_parsers import PydanticOutputParser\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "\n",
    "class Person(BaseModel):\n",
    "    \"\"\"Information about a person.\"\"\"\n",
    "\n",
    "    name: str = Field(..., description=\"The name of the person\")\n",
    "    height_in_meters: float = Field(\n",
    "        ..., description=\"The height of the person expressed in meters.\"\n",
    "    )\n",
    "\n",
    "\n",
    "class People(BaseModel):\n",
    "    \"\"\"Identifying information about all people in a text.\"\"\"\n",
    "\n",
    "    people: List[Person]\n",
    "\n",
    "\n",
    "# Set up a parser\n",
    "parser = PydanticOutputParser(pydantic_object=People)\n",
    "\n",
    "# Prompt\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            \"Answer the user query. Wrap the output in `json` tags\\n{format_instructions}\",\n",
    "        ),\n",
    "        (\"human\", \"{query}\"),\n",
    "    ]\n",
    ").partial(format_instructions=parser.get_format_instructions())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "6305de1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "System: Answer the user query. Wrap the output in `json` tags\n",
      "The output should be formatted as a JSON instance that conforms to the JSON schema below.\n",
      "\n",
      "As an example, for the schema {\"properties\": {\"foo\": {\"title\": \"Foo\", \"description\": \"a list of strings\", \"type\": \"array\", \"items\": {\"type\": \"string\"}}}, \"required\": [\"foo\"]}\n",
      "the object {\"foo\": [\"bar\", \"baz\"]} is a well-formatted instance of the schema. The object {\"properties\": {\"foo\": [\"bar\", \"baz\"]}} is not well-formatted.\n",
      "\n",
      "Here is the output schema:\n",
      "```\n",
      "{\"$defs\": {\"Person\": {\"description\": \"Information about a person.\", \"properties\": {\"name\": {\"description\": \"The name of the person\", \"title\": \"Name\", \"type\": \"string\"}, \"height_in_meters\": {\"description\": \"The height of the person expressed in meters.\", \"title\": \"Height In Meters\", \"type\": \"number\"}}, \"required\": [\"name\", \"height_in_meters\"], \"title\": \"Person\", \"type\": \"object\"}}, \"description\": \"Identifying information about all people in a text.\", \"properties\": {\"people\": {\"items\": {\"$ref\": \"#/$defs/Person\"}, \"title\": \"People\", \"type\": \"array\"}}, \"required\": [\"people\"]}\n",
      "```\n",
      "Human: Anna is 23 years old and she is 6 feet tall\n"
     ]
    }
   ],
   "source": [
    "query = \"Anna is 23 years old and she is 6 feet tall\"\n",
    "\n",
    "print(prompt.invoke({\"query\": query}).to_string())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "5e85dffc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "People(people=[Person(name='Anna', height_in_meters=1.8288)])"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# And now let's invoke it:\n",
    "\n",
    "chain = prompt | llm | parser\n",
    "\n",
    "chain.invoke({\"query\": query})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd7d8662",
   "metadata": {},
   "source": [
    "Custom Parsing\n",
    "You can also create a custom prompt and parser with LangChain Expression Language (LCEL), using a plain function to parse the output from the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "153b0b8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\erdkg\\AppData\\Local\\Temp\\ipykernel_19860\\1836477667.py:36: PydanticDeprecatedSince20: The `schema` method is deprecated; use `model_json_schema` instead. Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.11/migration/\n",
      "  ).partial(schema=People.schema())\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import re\n",
    "from typing import List\n",
    "\n",
    "from langchain_core.messages import AIMessage\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "\n",
    "class Person(BaseModel):\n",
    "    \"\"\"Information about a person.\"\"\"\n",
    "\n",
    "    name: str = Field(..., description=\"The name of the person\")\n",
    "    height_in_meters: float = Field(\n",
    "        ..., description=\"The height of the person expressed in meters.\"\n",
    "    )\n",
    "\n",
    "\n",
    "class People(BaseModel):\n",
    "    \"\"\"Identifying information about all people in a text.\"\"\"\n",
    "\n",
    "    people: List[Person]\n",
    "\n",
    "\n",
    "# Prompt\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            \"Answer the user query. Output your answer as JSON that  \"\n",
    "            \"matches the given schema: \\`\\`\\`json\\n{schema}\\n\\`\\`\\`. \"\n",
    "            \"Make sure to wrap the answer in \\`\\`\\`json and \\`\\`\\` tags\",\n",
    "        ),\n",
    "        (\"human\", \"{query}\"),\n",
    "    ]\n",
    ").partial(schema=People.schema())\n",
    "\n",
    "\n",
    "# Custom parser\n",
    "def extract_json(message: AIMessage) -> List[dict]:\n",
    "    \"\"\"Extracts JSON content from a string where JSON is embedded between \\`\\`\\`json and \\`\\`\\` tags.\n",
    "\n",
    "    Parameters:\n",
    "        text (str): The text containing the JSON content.\n",
    "\n",
    "    Returns:\n",
    "        list: A list of extracted JSON strings.\n",
    "    \"\"\"\n",
    "    text = message.content\n",
    "    # Define the regular expression pattern to match JSON blocks\n",
    "    pattern = r\"\\`\\`\\`json(.*?)\\`\\`\\`\"\n",
    "\n",
    "    # Find all non-overlapping matches of the pattern in the string\n",
    "    matches = re.findall(pattern, text, re.DOTALL)\n",
    "\n",
    "    # Return the list of matched JSON strings, stripping any leading or trailing whitespace\n",
    "    try:\n",
    "        return [json.loads(match.strip()) for match in matches]\n",
    "    except Exception:\n",
    "        raise ValueError(f\"Failed to parse: {message}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "2e3bc357",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "System: Answer the user query. Output your answer as JSON that  matches the given schema: \\`\\`\\`json\n",
      "{'$defs': {'Person': {'description': 'Information about a person.', 'properties': {'name': {'description': 'The name of the person', 'title': 'Name', 'type': 'string'}, 'height_in_meters': {'description': 'The height of the person expressed in meters.', 'title': 'Height In Meters', 'type': 'number'}}, 'required': ['name', 'height_in_meters'], 'title': 'Person', 'type': 'object'}}, 'description': 'Identifying information about all people in a text.', 'properties': {'people': {'items': {'$ref': '#/$defs/Person'}, 'title': 'People', 'type': 'array'}}, 'required': ['people'], 'title': 'People', 'type': 'object'}\n",
      "\\`\\`\\`. Make sure to wrap the answer in \\`\\`\\`json and \\`\\`\\` tags\n",
      "Human: Anna is 23 years old and she is 6 feet tall\n"
     ]
    }
   ],
   "source": [
    "query = \"Anna is 23 years old and she is 6 feet tall\"\n",
    "\n",
    "print(prompt.format_prompt(query=query).to_string())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "f01ed4a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'people': [{'name': 'Anna', 'height_in_meters': 1.829}]}]"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain = prompt | llm | extract_json\n",
    "\n",
    "chain.invoke({\"query\": query})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75cd6e6f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
