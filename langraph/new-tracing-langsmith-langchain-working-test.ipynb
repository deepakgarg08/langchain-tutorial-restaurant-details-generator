{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4bd10fb1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LANGCHAIN_API_KEY: \"lsv2_pt_b ...\n",
      "LANGCHAIN_TRACING_V2: true\n",
      "LANGCHAIN_PROJECT: \"default\" # or any other project name\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "print(\"LANGCHAIN_API_KEY:\", os.environ.get(\"LANGCHAIN_API_KEY\")[:10], \"...\")\n",
    "print(\"LANGCHAIN_TRACING_V2:\", os.environ.get(\"LANGCHAIN_TRACING_V2\"))\n",
    "print(\"LANGCHAIN_PROJECT:\", os.environ.get(\"LANGCHAIN_PROJECT\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "49b947fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import logging\n",
    "# logging.basicConfig(level=logging.DEBUG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "eb836e2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìù Story: AI whispered secrets of the universe, changing humanity forevermore.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:langsmith.client:Sending compressed multipart request with context: trace=142544c9-f623-4b1f-950a-949c59c15b38,id=142544c9-f623-4b1f-950a-949c59c15b38; trace=142544c9-f623-4b1f-950a-949c59c15b38,id=53dcffbf-0594-4eb9-9754-5a01c4631f6d; trace=142544c9-f623-4b1f-950a-949c59c15b38,id=53dcffbf-0594-4eb9-9754-5a01c4631f6d; trace=142544c9-f623-4b1f-950a-949c59c15b38,id=f68079bf-5f39-466e-8488-46945ce0ec30\n",
      "DEBUG:urllib3.connectionpool:https://api.smith.langchain.com:443 \"POST /runs/multipart HTTP/1.1\" 202 34\n",
      "DEBUG:langsmith.client:Sending compressed multipart request with context: trace=142544c9-f623-4b1f-950a-949c59c15b38,id=f68079bf-5f39-466e-8488-46945ce0ec30; trace=142544c9-f623-4b1f-950a-949c59c15b38,id=d74d792f-2d50-476e-9c8f-35702a8a2311; trace=142544c9-f623-4b1f-950a-949c59c15b38,id=d74d792f-2d50-476e-9c8f-35702a8a2311; trace=142544c9-f623-4b1f-950a-949c59c15b38,id=142544c9-f623-4b1f-950a-949c59c15b38\n",
      "DEBUG:urllib3.connectionpool:https://api.smith.langchain.com:443 \"POST /runs/multipart HTTP/1.1\" 202 34\n"
     ]
    }
   ],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import RunnableConfig\n",
    "\n",
    "prompt = ChatPromptTemplate.from_template(\"Write a 10-word story about AI.\")\n",
    "llm = ChatOpenAI(model=\"gpt-4o\")\n",
    "parser = StrOutputParser()\n",
    "\n",
    "chain = prompt | llm | parser\n",
    "\n",
    "config = RunnableConfig(configurable={\"run_name\": \"ai_story_final_trace\"})\n",
    "\n",
    "response = chain.invoke({}, config=config)\n",
    "print(\"üìù Story:\", response)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6b14a918",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:openai._base_client:Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'idempotency_key': 'stainless-python-retry-7b580983-c0de-4fd1-b60e-15897d8003ab', 'json_data': {'messages': [{'content': 'Write a short sentence about LLMs in 10 word.', 'role': 'user'}], 'model': 'gpt-4o', 'stream': False}}\n",
      "DEBUG:openai._base_client:Sending HTTP Request: POST https://api.openai.com/v1/chat/completions\n",
      "DEBUG:httpcore.connection:close.started\n",
      "DEBUG:httpcore.connection:close.complete\n",
      "DEBUG:httpcore.connection:connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None\n",
      "DEBUG:httpcore.connection:connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x0000015BE439E9B0>\n",
      "DEBUG:httpcore.connection:start_tls.started ssl_context=<ssl.SSLContext object at 0x0000015BDCF4BC40> server_hostname='api.openai.com' timeout=None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:httpcore.connection:start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x0000015BE439EAA0>\n",
      "DEBUG:httpcore.http11:send_request_headers.started request=<Request [b'POST']>\n",
      "DEBUG:httpcore.http11:send_request_headers.complete\n",
      "DEBUG:httpcore.http11:send_request_body.started request=<Request [b'POST']>\n",
      "DEBUG:httpcore.http11:send_request_body.complete\n",
      "DEBUG:httpcore.http11:receive_response_headers.started request=<Request [b'POST']>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ API Key: \"lsv2_pt_b\n",
      "‚úÖ Project: \"default\" # or any other project name\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:httpcore.http11:receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Tue, 08 Jul 2025 10:00:48 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'user-gtr8okzcelt85cunctoidups'), (b'openai-processing-ms', b'566'), (b'openai-version', b'2020-10-01'), (b'x-envoy-upstream-service-time', b'579'), (b'x-ratelimit-limit-requests', b'500'), (b'x-ratelimit-limit-tokens', b'30000'), (b'x-ratelimit-remaining-requests', b'499'), (b'x-ratelimit-remaining-tokens', b'29986'), (b'x-ratelimit-reset-requests', b'120ms'), (b'x-ratelimit-reset-tokens', b'28ms'), (b'x-request-id', b'req_272e0528670ddbb794d3da82b583ef44'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'cf-cache-status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'95bebc92ea6a91de-FRA'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=\":443\"; ma=86400')])\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "DEBUG:httpcore.http11:receive_response_body.started request=<Request [b'POST']>\n",
      "DEBUG:httpcore.http11:receive_response_body.complete\n",
      "DEBUG:httpcore.http11:response_closed.started\n",
      "DEBUG:httpcore.http11:response_closed.complete\n",
      "DEBUG:openai._base_client:HTTP Response: POST https://api.openai.com/v1/chat/completions \"200 OK\" Headers({'date': 'Tue, 08 Jul 2025 10:00:48 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'access-control-expose-headers': 'X-Request-ID', 'openai-organization': 'user-gtr8okzcelt85cunctoidups', 'openai-processing-ms': '566', 'openai-version': '2020-10-01', 'x-envoy-upstream-service-time': '579', 'x-ratelimit-limit-requests': '500', 'x-ratelimit-limit-tokens': '30000', 'x-ratelimit-remaining-requests': '499', 'x-ratelimit-remaining-tokens': '29986', 'x-ratelimit-reset-requests': '120ms', 'x-ratelimit-reset-tokens': '28ms', 'x-request-id': 'req_272e0528670ddbb794d3da82b583ef44', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'cf-cache-status': 'DYNAMIC', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '95bebc92ea6a91de-FRA', 'content-encoding': 'gzip', 'alt-svc': 'h3=\":443\"; ma=86400'})\n",
      "DEBUG:openai._base_client:request_id: req_272e0528670ddbb794d3da82b583ef44\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üß† Output: LLMs generate human-like text, transforming communication, creativity, and technology.\n"
     ]
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import RunnableConfig\n",
    "import os\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "# Confirm env\n",
    "print(\"‚úÖ API Key:\", os.environ.get(\"LANGCHAIN_API_KEY\")[:10])\n",
    "print(\"‚úÖ Project:\", os.environ.get(\"LANGCHAIN_PROJECT\"))\n",
    "\n",
    "llm = ChatOpenAI(model=\"gpt-4o\")\n",
    "\n",
    "prompt = ChatPromptTemplate.from_template(\"Write a short sentence about LLMs in 10 word.\")\n",
    "parser = StrOutputParser()\n",
    "\n",
    "chain = prompt | llm | parser\n",
    "\n",
    "config = RunnableConfig(configurable={\"run_name\": \"llm_trace_test\"})\n",
    "\n",
    "response = chain.invoke({}, config=config)\n",
    "print(\"üß† Output:\", response)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9b63f20",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a8aab8ba",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (3126332150.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[7], line 1\u001b[1;36m\u001b[0m\n\u001b[1;33m    DEBUG:langsmith.client:Posting run to LangSmith...\u001b[0m\n\u001b[1;37m                          ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "DEBUG:langsmith.client:Posting run to LangSmith...\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa82e2ac",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
