{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37a256f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install -U langgraph \"langchain[anthropic]\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0e5f194",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb0544c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# to check the current Python environment\n",
    "import sys\n",
    "print(sys.prefix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "740794a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "# Load variables from .env into environment\n",
    "load_dotenv()\n",
    "\n",
    "# Get the OpenAI API key\n",
    "# os.getenv(\"OPENAI_API_KEY\")\n",
    "# ANTHROPIC_API_KEY = os.getenv(\"ANTHROPIC_API_KEY\")\n",
    "\n",
    "# Use the key\n",
    "# print(f\"OpenAI API Key: {api_key} \\n {ANTHROPIC_API_KEY}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30369471",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "assert \"ANTHROPIC_API_KEY\" in os.environ\n",
    "assert \"OPENAI_API_KEY\" in os.environ\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "269f1a1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.prebuilt import create_react_agent\n",
    "\n",
    "def get_weather(city: str) -> str:  \n",
    "    \"\"\"Get weather for a given city.\"\"\"\n",
    "    return f\"It's always sunny in {city}!\"\n",
    "\n",
    "agent = create_react_agent(\n",
    "    # model=\"anthropic:claude-3-7-sonnet-latest\",  \n",
    "    # model=\"anthropic:claude-3-7-sonnet-latest\",\n",
    "    model = \"gpt-4o-mini\",  \n",
    "    tools=[get_weather],  \n",
    "    prompt=\"You are a helpful assistant\"  \n",
    ")\n",
    "\n",
    "# Run the agent\n",
    "response = agent.invoke(\n",
    "    {\"messages\": [{\"role\": \"user\", \"content\": \"wite 20 words story?\"}]}\n",
    ")\n",
    "pprint(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "980e972d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "print(\"LANGCHAIN_TRACING_V2:\", os.environ.get(\"LANGCHAIN_TRACING_V2\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b018b113",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv()\n",
    "\n",
    "# Confirm values\n",
    "print(\"LangSmith Project:\", os.environ.get(\"LANGCHAIN_PROJECT\"))\n",
    "print(\"LangSmith Tracing:\", os.environ.get(\"LANGCHAIN_TRACING_V2\"))\n",
    "print(\"LangSmith API Key:\", os.environ.get(\"LANGCHAIN_API_KEY\")[:8], \"...\")  # Just to check if set\n",
    "\n",
    "# Run LLM call\n",
    "llm = ChatOpenAI(model=\"gpt-4o\")\n",
    "response = llm.invoke(\"Hello, LangSmith!\")\n",
    "print(\"Response:\", response)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0901d54d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.prebuilt import create_react_agent\n",
    "from langchain_core.runnables import RunnableConfig  # required for metadata/tracing\n",
    "\n",
    "def get_weather(city: str) -> str:  \n",
    "    return f\"It's always sunny in {city}!\"\n",
    "\n",
    "agent = create_react_agent(\n",
    "    model=\"openai:gpt-4o\",\n",
    "    tools=[get_weather],\n",
    "    prompt=\"You are a helpful assistant\"\n",
    ")\n",
    "\n",
    "# Add tracing metadata via config\n",
    "config = RunnableConfig(configurable={\"run_name\": \"weather_story_test\"})\n",
    "\n",
    "response = agent.invoke(\n",
    "    {\"messages\": [{\"role\": \"user\", \"content\": \"write 20 word story?\"}]},\n",
    "    config=config\n",
    ")\n",
    "from pprint import pprint\n",
    "pprint(response)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48c18215",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.runnables import RunnableConfig\n",
    "\n",
    "llm = ChatOpenAI(model=\"gpt-4o\")\n",
    "\n",
    "prompt = ChatPromptTemplate.from_template(\"Write a 20 word story.\")\n",
    "chain = prompt | llm\n",
    "\n",
    "response = chain.invoke({}, config=RunnableConfig(configurable={\"run_name\": \"basic_story_run\"}))\n",
    "print(response.content)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa30ec9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.runnables import RunnableConfig\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "# Load env\n",
    "load_dotenv()\n",
    "\n",
    "# Define LLM and prompt\n",
    "llm = ChatOpenAI(model=\"gpt-4o\")\n",
    "prompt = ChatPromptTemplate.from_template(\"Write a 20 word story.\")\n",
    "\n",
    "# Define the full chain (this is required for tracing)\n",
    "chain = prompt | llm | StrOutputParser()\n",
    "\n",
    "# Add trace config\n",
    "config = RunnableConfig(configurable={\"run_name\": \"traceable_20_word_story\"})\n",
    "\n",
    "# Run\n",
    "response = chain.invoke({}, config=config)\n",
    "print(\"Story:\", response)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de9bfdd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langsmith.client import Client\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "# You can also pass project name from your .env\n",
    "client = Client()\n",
    "\n",
    "# If you already set LANGCHAIN_PROJECT in your .env, use it\n",
    "# project_name = \"default\"\n",
    "\n",
    "project = client.read_project(project_name=project_name)\n",
    "print(f\"âœ… LangSmith connection successful. Project: {project.name}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "119cfa9f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
